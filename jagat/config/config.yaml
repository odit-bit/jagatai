server:
  address: "127.0.0.1:11823" #default server address listening to
  debug: false

provider: # llm backend
  name: "ollama"
  model: "qwen3:1.7b" #Default
  apikey: "" # JAGATAI_PROVIDER_APIKEY
  extra:
    endpoint: #custom endpoint ollama only
    topP:
    topK:
    minP:
    temperature:

tools:
  - name: "clock"
  - name: "osm"
  - name: "openmeteo"
    endpoint: "https://api.open-meteo.com"

observability:
  enable: false
  exporter: "stdout" # stdout or jaeger
  traceendpoint: ""
  metricendpoint: ""
  secure: false
